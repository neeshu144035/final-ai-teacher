{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eaf30f-2132-49e6-be07-e2263bc7ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"knowledgebase.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "texts = []\n",
    "metadata = []\n",
    "\n",
    "for chapter, topics in data.items():\n",
    "    for topic_title, topic_content in topics.items():\n",
    "       \n",
    "        texts.append(f\"{topic_title}: {topic_content}\")\n",
    "        metadata.append({\"title\": topic_title, \"chapter\": chapter})\n",
    "\n",
    "embeddings = model.encode(texts, convert_to_numpy=True)\n",
    "\n",
    "print(f\"Number of embeddings: {embeddings.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f25aa0-8b1f-4ccb-9ba1-57c43fdaf18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)  \n",
    "index.add(embeddings)  \n",
    "\n",
    "faiss.write_index(index, \"textbook_faiss.index\")\n",
    "\n",
    "with open(\"metadata.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a64fa8-531e-491f-909c-e8e69d3b2b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, top_k=3):\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(indices[0])):\n",
    "        idx = indices[0][i]\n",
    "        results.append({\n",
    "            \"title\": metadata[idx][\"title\"],  \n",
    "            \"chapter\": metadata[idx][\"chapter\"],  \n",
    "            \"score\": distances[0][i]\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "query = \"Right-Hand Thumb Rule\"\n",
    "results = search(query)\n",
    "\n",
    "for res in results:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d17cc7f-8a01-4810-8152-bf9e478233d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"knowledgebase.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def get_explanation(query, top_k=1):\n",
    "    results = search(query, top_k)\n",
    "    \n",
    "    if not results:\n",
    "        return \"No relevant information found.\"\n",
    "    \n",
    "    best_match = results[0]  # Get the top-ranked result\n",
    "    best_title = best_match[\"title\"]\n",
    "    best_chapter = best_match[\"chapter\"]\n",
    "\n",
    "    # Search JSON structure for the matching content\n",
    "    if best_chapter in data:\n",
    "        for topic_title, topic_content in data[best_chapter].items():\n",
    "            if topic_title == best_title:\n",
    "                return topic_content  \n",
    "\n",
    "    return \"No relevant information found.\"\n",
    "\n",
    "\n",
    "query = \"2.2.1 What Happens to an Acid or a Base in a Water Solution?\"\n",
    "explanation = get_explanation(query)\n",
    "print(\"Explanation:\", explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2ed03d-5a57-4cf6-aa69-d817ee9ce072",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = \"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\"  # Replace with your actual Groq API key\n",
    "GOOGLE_API_KEY = \"AIzaSyB8KDnZnqhfj5Ll1DOHksrcx_dMgeP-VaQ\"  # Replace with your actual Google API key\n",
    "CX = \"c330687bc6e014984\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62110651-fc45-423f-9a79-27c011b313f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed25cf-250d-477a-9e59-1bfff123f3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "793e760e-9a95-4159-b490-6395d849774e",
   "metadata": {},
   "source": [
    "# final code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8451b4-de19-402f-b909-491d15a693e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "import requests\n",
    "import random\n",
    "import yt_dlp\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "\n",
    "debug_mode = True  # Enable debugging\n",
    "def debug_print(message, level=1):\n",
    "    if debug_mode:\n",
    "        prefix = \"  \" * level\n",
    "        print(f\"{prefix}üîπ {message}\")\n",
    "\n",
    "\n",
    "# Configuration & Data Loading\n",
    "\n",
    "IMAGE_DIR = \"images\"\n",
    "FIGURES_JSON = \"output.json\"\n",
    "\n",
    "\n",
    "with open(\"knowledgebase.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    kb_data = json.load(f)\n",
    "with open(\"metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Normalize function for matching\n",
    "def normalize_title(title):\n",
    "    return title.strip().lower()\n",
    "\n",
    "# Create normalized KB lookup\n",
    "normalized_kb = {}\n",
    "for chapter, topics in kb_data.items():\n",
    "    for title, content in topics.items():\n",
    "        norm_key = (chapter, normalize_title(title))\n",
    "        normalized_kb[norm_key] = content\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "index = faiss.read_index(\"textbook_faiss.index\") \n",
    "\n",
    "def search(query, top_k=5, similarity_threshold=0.98, mode=\"hybrid\"):\n",
    "    norm_query = normalize_title(query)\n",
    "    results = []\n",
    "    seen_embeddings = []\n",
    "    seen_titles = set()\n",
    "\n",
    "    def get_exact_matches():\n",
    "        for item in metadata:\n",
    "            title = item[\"title\"]\n",
    "            chapter = item[\"chapter\"]\n",
    "            norm_title = normalize_title(title)\n",
    "            if norm_query in norm_title:\n",
    "                norm_key = (chapter, norm_title)\n",
    "                content = normalized_kb.get(norm_key)\n",
    "                if content:\n",
    "                    seen_titles.add(norm_key)\n",
    "                    return [{\n",
    "                        \"title_key\": title,\n",
    "                        \"chapter\": chapter,\n",
    "                        \"score\": 0.0,\n",
    "                        \"content\": content\n",
    "                    }]\n",
    "        return []\n",
    "\n",
    "    def get_semantic_matches():\n",
    "        query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "        distances, indices = index.search(query_embedding, top_k)\n",
    "        semantic_results = []\n",
    "\n",
    "        for i in range(len(indices[0])):\n",
    "            idx = indices[0][i]\n",
    "            raw_title = metadata[idx][\"title\"]\n",
    "            chapter = metadata[idx][\"chapter\"]\n",
    "            norm_key = (chapter, normalize_title(raw_title))\n",
    "            content = normalized_kb.get(norm_key)\n",
    "\n",
    "            if content and norm_key not in seen_titles:\n",
    "                content_embedding = model.encode(content, convert_to_tensor=True)\n",
    "\n",
    "                \n",
    "                is_duplicate = False\n",
    "                for prev_emb in seen_embeddings:\n",
    "                    if util.cos_sim(content_embedding, prev_emb).item() >= similarity_threshold:\n",
    "                        is_duplicate = True\n",
    "                        break\n",
    "\n",
    "                if not is_duplicate:\n",
    "                    seen_embeddings.append(content_embedding)\n",
    "                    seen_titles.add(norm_key)\n",
    "                    semantic_results.append({\n",
    "                        \"title_key\": raw_title,\n",
    "                        \"chapter\": chapter,\n",
    "                        \"score\": distances[0][i],\n",
    "                        \"content\": content\n",
    "                    })\n",
    "        return semantic_results\n",
    "\n",
    "    # MODE HANDLING\n",
    "    if mode == \"exact\":\n",
    "        results = get_exact_matches()\n",
    "    elif mode == \"semantic\":\n",
    "        results = get_semantic_matches()\n",
    "    else:  # hybrid\n",
    "        results = get_exact_matches()\n",
    "        if not results:\n",
    "            results = get_semantic_matches()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Part 1: Textual Lesson Generation Using RAG & LLM\n",
    "# Load FAISS index for textbook retrieval (already done above)\n",
    "# Load SBERT model for text retrieval (already done above)\n",
    "\n",
    "# Groq LLM API configuration (replace with your actual API key)\n",
    "LLM_API_KEY = \"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\"\n",
    "LLM_API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Data & FAISS index for figure retrieval\n",
    "def load_figures():\n",
    "    with open(FIGURES_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "figures_data = load_figures()\n",
    "\n",
    "# Initialize FAISS and embedding model for image retrieval\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\").to(device)\n",
    "\n",
    "FAISS_INDEX_FILE = \"subchapter_faiss.index\"\n",
    "METADATA_FILE = \"subchapter_metadata.json\"\n",
    "\n",
    "\n",
    "index_figures = faiss.read_index(FAISS_INDEX_FILE)\n",
    "\n",
    "\n",
    "with open(METADATA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata_figures = json.load(f)\n",
    "\n",
    "def search_exact_subchapter(query, top_k=1):\n",
    "    \"\"\"Find the most relevant subchapter using FAISS.\"\"\"\n",
    "    debug_print(f\"Searching for exact subchapter match: {query}\")\n",
    "    query_embedding = image_model.encode([query], convert_to_numpy=True).astype('float32')\n",
    "    _, indices = index_figures.search(query_embedding.reshape(1, -1), top_k)\n",
    "\n",
    "    best_match_index = str(indices[0][0])\n",
    "    best_subchapter = metadata_figures.get(best_match_index, None)\n",
    "    debug_print(f\"Best match subchapter: {best_subchapter}\", 2)\n",
    "    return best_subchapter\n",
    "\n",
    "def get_image_path(figure_ref):\n",
    "    \"\"\"Find image path with multiple fallback patterns.\"\"\"\n",
    "    debug_print(f\"Locating image for: {figure_ref}\", 2)\n",
    "    base_name = figure_ref.replace(\" \", \"_\")\n",
    "    attempts = [\n",
    "        f\"{base_name}.png\",\n",
    "        f\"{base_name}.jpg\",\n",
    "        f\"figure_{base_name}.png\"\n",
    "    ]\n",
    "    for attempt in attempts:\n",
    "        test_path = os.path.join(IMAGE_DIR, attempt)\n",
    "        if os.path.exists(test_path):\n",
    "            debug_print(f\"‚úÖ Found image at: {test_path}\", 3)\n",
    "            return test_path\n",
    "    debug_print(\"‚ùå No valid image path found\", 3)\n",
    "    return None\n",
    "\n",
    "def fetch_figures_only(subchapter_name): # Changed parameter name to be more explicit\n",
    "    \"\"\"Retrieve only figures (images + raw descriptions) for a given subchapter.\"\"\"\n",
    "    debug_print(f\"Retrieving figures for subchapter: {subchapter_name}\")\n",
    "    figures = [fig for fig in figures_data if fig[\"subchapter\"] == subchapter_name]\n",
    "    if not figures:\n",
    "        debug_print(f\"No relevant figures found for subchapter: {subchapter_name}\")\n",
    "        return \"No relevant figures found.\"\n",
    "    figure_blocks = []\n",
    "    for fig in figures:\n",
    "        fig_path = get_image_path(fig['figure'])\n",
    "        if fig_path:\n",
    "            figure_blocks.append({\n",
    "                \"name\": fig['figure'],\n",
    "                \"path\": fig_path,\n",
    "                \"desc\": fig['description']\n",
    "            })\n",
    "    \n",
    "    for fig in figure_blocks:\n",
    "        print(f\"\\n{fig['name']}: {fig['desc']}\")\n",
    "        try:\n",
    "            display(Image(filename=fig['path']))\n",
    "        except Exception as e:\n",
    "            debug_print(f\"‚ö† Couldn't display image: {str(e)}\")\n",
    "    return figure_blocks\n",
    "\n",
    "\n",
    "# Revised Figure Retrieval for Lesson Multimedia Integration\n",
    "\n",
    "def retrieve_and_expand_figures(query):\n",
    "    \"\"\"\n",
    "    Retrieve figures related to the query by using the title of the\n",
    "    most relevant text content and generate HTML to display them.\n",
    "    \"\"\"\n",
    "    search_results = search(query, mode=\"hybrid\", top_k=1)\n",
    "    if not search_results:\n",
    "        return \"<p>No relevant text found for image retrieval.</p>\"\n",
    "\n",
    "    best_text_match = search_results[0]\n",
    "    subchapter_name = best_text_match[\"title_key\"] # Use the title_key as the subchapter name\n",
    "\n",
    "    blocks = fetch_figures_only(subchapter_name)\n",
    "    if isinstance(blocks, str):\n",
    "        # An error message was returned\n",
    "        return f\"<p>{blocks}</p>\"\n",
    "\n",
    "    figure_html = \"<div style='margin-top: 20px;'><h3>üìä Visual Aids</h3>\"\n",
    "    # Limit to 3 figures\n",
    "    for fig in blocks[:3]:\n",
    "        clean_desc = fig['desc']  \n",
    "        figure_html += f\"\"\"\n",
    "        <div style='margin-bottom: 20px; border: 1px solid #ddd; padding: 10px; border-radius: 5px;'>\n",
    "            <img src='{fig['path']}' style='max-width: 100%; height: auto; display: block; margin: 0 auto;'>\n",
    "            <p style='text-align: center; font-style: italic;'>{clean_desc or 'Visual demonstration'}</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    figure_html += \"</div>\"\n",
    "    return figure_html\n",
    "\n",
    "\n",
    "# Functions for Video & Lesson Generation remain unchanged (with the modification to use the new generate_text_lesson)\n",
    "\n",
    "def fetch_animated_videos(topic, num_videos=1):\n",
    "    search_query = f\"ytsearch{num_videos}:{topic} animation explained in english\"\n",
    "    print(f\"Searching for: {search_query}\")  \n",
    "\n",
    "    ydl_opts = {\n",
    "        \"quiet\": True,\n",
    "        \"extract_flat\": True,\n",
    "        \"force_generic_extractor\": True\n",
    "    }\n",
    "    \n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(search_query, download=False)\n",
    "        \n",
    "        if \"entries\" in info and len(info[\"entries\"]) > 0:\n",
    "            video = info[\"entries\"][0]\n",
    "            print(f\"Found video: {video['title']}\")  \n",
    "            if video.get(\"duration\", 301) <= 300:\n",
    "                return {\n",
    "                    \"title\": video[\"title\"],\n",
    "                    \"url\": video[\"url\"],\n",
    "                    \"id\": video[\"id\"]\n",
    "                }\n",
    "    return None\n",
    "\n",
    "def generate_topic_hook(topic):\n",
    "    \"\"\"Generate a short, engaging hook for the topic using the LLM.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are a science educator. Create a SHORT (1-2 sentences), engaging hook for the topic *{topic}* for 8th-grade students using one of these techniques:\n",
    "- A surprising fact/question\n",
    "- A relatable analogy/metaphor\n",
    "- A real-world application\n",
    "- A mini thought experiment\n",
    "\n",
    "Return ONLY the hook.\n",
    "\"\"\"\n",
    "    response = requests.post(\n",
    "        LLM_API_URL,\n",
    "        headers={\"Authorization\": f\"Bearer {LLM_API_KEY}\"},\n",
    "        json={\n",
    "            \"model\": \"llama3-70b-8192\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_tokens\": 1000,\n",
    "            \"temperature\": 0.9\n",
    "        }\n",
    "    )\n",
    "    hook = response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    return hook\n",
    "\n",
    "def generate_funny_intro(topic):\n",
    "    \"\"\"Generate an introduction that begins with a funny story or meme about the topic.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are a creative and humorous science educator. Tell a short, funny story or describe a relatable meme about *{topic}* to engage 8th-grade students. Avoid using video introductions. Return ONLY the story.\n",
    "\"\"\"\n",
    "    response = requests.post(\n",
    "        LLM_API_URL,\n",
    "        headers={\"Authorization\": f\"Bearer {LLM_API_KEY}\"},\n",
    "        json={\n",
    "            \"model\": \"llama3-70b-8192\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_tokens\": 1000,\n",
    "            \"temperature\": 0.9\n",
    "        }\n",
    "    )\n",
    "    funny_intro = response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    return funny_intro\n",
    "\n",
    "def generate_dynamic_intro(topic):\n",
    "    \"\"\"Generate an introductory paragraph with a funny story or meme.\"\"\"\n",
    "    funny_intro = generate_funny_intro(topic)\n",
    "    hook = generate_topic_hook(topic)\n",
    "    return f\"\"\"\n",
    "<p>{funny_intro}</p>\n",
    "<p>{hook}</p>\n",
    "<p>Today, we're exploring the fascinating world of <strong>{topic}</strong>! üîç<br>\n",
    "Quick prediction: What do you think happens when...? Let's find out in our lesson!</p>\n",
    "\"\"\"\n",
    "\n",
    "def generate_text_lesson(query):\n",
    "    \"\"\"Generate a dynamic lesson using the FAISS-retrieved textbook content\n",
    "    using the new hybrid search as the main explanation.\"\"\"\n",
    "    debug_print(f\"Searching for relevant text using hybrid search: {query}\")\n",
    "    search_results = search(query, mode=\"hybrid\", top_k=1) # Adjust top_k as needed\n",
    "    if not search_results:\n",
    "        return \"<p>No relevant information found.</p>\"\n",
    "    \n",
    "    best_match = search_results[0]\n",
    "    retrieved_content = best_match[\"content\"]\n",
    "    cleaned_title = re.sub(r\"^\\d+(\\.\\d+)*\\s*\", \"\", best_match[\"title_key\"]).strip()\n",
    "    introduction = generate_dynamic_intro(cleaned_title)\n",
    "    # Enhanced Explanation Generation from Textbook Content via LLM\n",
    "    prompt = f\"\"\"\n",
    "You are an engaging, fun-loving, and knowledgeable 8th-grade science teacher.\n",
    "Below is the textbook content for the topic titled '{cleaned_title}'.\n",
    "Your task is to generate a richly detailed, smooth, and engaging explanation that:\n",
    "- Uses every sentence from the textbook content as a base.\n",
    "- Expands each idea with real-life analogies, fun facts, surprising trivia, and interesting stories kids can relate to.\n",
    "- Breaks down complex terms into simple, visual language.\n",
    "- Feels like a passionate teacher telling a story, not reading a script.\n",
    "- Uses HTML with <h2>, <h3>, <p>, and <ul><li> where helpful.\n",
    "- Ensures smooth transitions between paragraphs.\n",
    "Textbook Content:\n",
    "\"{retrieved_content}\"\n",
    "\"\"\"\n",
    "    debug_print(\"Sending LLM request with enhanced textbook expansion prompt...\", 2)\n",
    "    response = requests.post(\n",
    "        LLM_API_URL,\n",
    "        headers={\"Authorization\": f\"Bearer {LLM_API_KEY}\"},\n",
    "        json={\n",
    "            \"model\": \"llama3-70b-8192\",\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"max_tokens\": 4000,\n",
    "            \"temperature\": 0.8\n",
    "        }\n",
    "    )\n",
    "    result = response.json()\n",
    "    if \"choices\" in result:\n",
    "        ai_explanation = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "    else:\n",
    "        ai_explanation = f\"<p>Error: {result}</p>\"\n",
    "    # Multimedia Integration: Figures & Video\n",
    "    multimedia_html = retrieve_and_expand_figures(query)\n",
    "    video = fetch_animated_videos(cleaned_title)\n",
    "    if video:\n",
    "        video_html = f\"\"\"\n",
    "        <div style='margin: 20px 0;'>\n",
    "            <h3>üé• Video Explanation</h3>\n",
    "            <p>Watch this short animation about {cleaned_title}:</p>\n",
    "            <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/{video['id']}\"\n",
    "                    frameborder=\"0\" allowfullscreen style='max-width: 100%;'></iframe>\n",
    "                    <p><em>{video['title']}</em></p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        multimedia_html += video_html\n",
    "    # Build the final lesson HTML\n",
    "    text_lesson_html = f\"\"\"\n",
    "    <div style=\"font-family: Arial, sans-serif;\">\n",
    "        <h2>üåü Introduction</h2>\n",
    "        {introduction}\n",
    "        <h2>üìö Deep Dive Explanation</h2>\n",
    "        <div>{ai_explanation}</div>\n",
    "        {multimedia_html}\n",
    "        <h2>üéì Key Takeaways</h2>\n",
    "        <p><strong>Summary:</strong> We covered all the key points in detail with stories,\n",
    "        analogies, and visuals that make learning fun and meaningful. Keep exploring!</p>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    return text_lesson_html\n",
    "\n",
    "# Final Integration: AI Teacher Lesson with Multimedia\n",
    "\n",
    "def generate_ai_teacher_lesson(query):\n",
    "    debug_print(\"Generating AI Teacher Lesson...\")\n",
    "    text_lesson_html = generate_text_lesson(query)\n",
    "    final_html = f\"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "      <style>\n",
    "        body {{ font-family: Arial, sans-serif; line-height: 1.6; }}\n",
    "        h2 {{ color: #2e6c80; }}\n",
    "        h3 {{ color: #3e8f3e; }}\n",
    "        h4 {{ color: #8a2be2; }}\n",
    "        .lesson-container {{ margin: 20px; }}\n",
    "      </style>\n",
    "    </head>\n",
    "    <body>\n",
    "      <div class=\"lesson-container\">\n",
    "        <h1 style=\"text-align: center;\">AI Teacher Lesson</h1>\n",
    "        {text_lesson_html}\n",
    "      </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    display(HTML(final_html))\n",
    "    return final_html\n",
    "\n",
    "\n",
    "final_lesson = generate_ai_teacher_lesson(\"MAGNETIC FIELD AND FIELD LINES\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (Jupyter)",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
